{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(actual, predicted):\n",
    "    return sum((a - p) ** 2 for a, p in zip(actual, predicted)) / len(actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gmm_synthetic_data(n_clusters, n_points, means, covariances, weights):\n",
    "    data = []\n",
    "    for _ in range(n_points):\n",
    "        cluster = np.random.choice(range(n_clusters), p=weights)\n",
    "        point = np.random.multivariate_normal(means[cluster], covariances[cluster])\n",
    "        data.append(point)\n",
    "    return np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def batch_norm(x, gamma, beta, epsilon=1e-5):\n",
    "    mean = np.mean(x, axis=0)\n",
    "    var = np.var(x, axis=0)\n",
    "    x_normalized = (x - mean) / np.sqrt(var + epsilon)\n",
    "    return gamma * x_normalized + beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sgd_logistic_regression(X, y, lr=0.01, epochs=100):\n",
    "    weights = np.zeros(X.shape[1])\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(y)):\n",
    "            gradient = (sigmoid(np.dot(X[i], weights)) - y[i]) * X[i]\n",
    "            weights -= lr * gradient\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def backpropagation(X, y, weights1, weights2, learning_rate):\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def sigmoid_derivative(z):\n",
    "        return z * (1 - z)\n",
    "    \n",
    "    # Forward pass\n",
    "    hidden_layer_input = np.dot(X, weights1)\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    final_output = sigmoid(np.dot(hidden_layer_output, weights2))\n",
    "    \n",
    "    # Backward pass\n",
    "    error = y - final_output\n",
    "    d_output = error * sigmoid_derivative(final_output)\n",
    "    \n",
    "    error_hidden_layer = d_output.dot(weights2.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "    \n",
    "    # Update weights\n",
    "    weights2 += hidden_layer_output.T.dot(d_output) * learning_rate\n",
    "    weights1 += X.T.dot(d_hidden_layer) * learning_rate\n",
    "    return weights1, weights2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, criterion='gini'):\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def gini(self, y):\n",
    "        m = len(y)\n",
    "        return 1 - sum((np.sum(y == c) / m) ** 2 for c in np.unique(y))\n",
    "\n",
    "    def entropy(self, y):\n",
    "        m = len(y)\n",
    "        return -sum((np.sum(y == c) / m) * np.log2(np.sum(y == c) / m) for c in np.unique(y))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # A simple implementation\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict based on the built tree\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    tp = sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    return 2 * (precision * recall) / (precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def hinge_loss(X, y, weights, bias):\n",
    "    return max(0, 1 - y * (np.dot(X, weights) + bias))\n",
    "\n",
    "def sgd_svm(X, y, lr=0.01, epochs=100):\n",
    "    weights = np.zeros(X.shape[1])\n",
    "    bias = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(y)):\n",
    "            if y[i] * (np.dot(X[i], weights) + bias) < 1:\n",
    "                weights -= lr * (-y[i] * X[i] + 0.01 * weights)\n",
    "                bias -= lr * (-y[i])\n",
    "            else:\n",
    "                weights -= lr * 0.01 * weights\n",
    "    return weights, bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(x, y):\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    return np.sum((x - x_mean) * (y - y_mean)) / np.sqrt(np.sum((x - x_mean)**2) * np.sum((y - y_mean)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def adagrad(X, y, lr=0.01, epochs=100):\n",
    "    weights = np.zeros(X.shape[1])\n",
    "    bias = 0\n",
    "    epsilon = 1e-8\n",
    "    gradient_accumulator = np.zeros(X.shape[1])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(y)):\n",
    "            prediction = np.dot(X[i], weights) + bias\n",
    "            error = prediction - y[i]\n",
    "            \n",
    "            gradient = error * X[i]\n",
    "            gradient_accumulator += gradient**2\n",
    "            adjusted_gradient = lr / (np.sqrt(gradient_accumulator) + epsilon)\n",
    "            \n",
    "            weights -= adjusted_gradient * gradient\n",
    "            bias -= lr * error\n",
    "            \n",
    "    return weights, bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def simulate_markov_chain(transition_matrix, initial_state, steps):\n",
    "    state = np.array(initial_state)\n",
    "    for _ in range(steps):\n",
    "        state = np.dot(state, transition_matrix)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.mean = np.zeros((len(self.classes), X.shape[1]))\n",
    "        self.var = np.zeros((len(self.classes), X.shape[1]))\n",
    "        self.priors = np.zeros(len(self.classes))\n",
    "        \n",
    "        for idx, c in enumerate(self.classes):\n",
    "            X_c = X[y == c]\n",
    "            self.mean[idx, :] = X_c.mean(axis=0)\n",
    "            self.var[idx, :] = X_c.var(axis=0)\n",
    "            self.priors[idx] = X_c.shape[0] / X.shape[0]\n",
    "            \n",
    "    def predict(self, X):\n",
    "        posteriors = []\n",
    "        for x in X:\n",
    "            posteriors.append(self._calculate_posterior(x))\n",
    "        return np.argmax(posteriors, axis=1)\n",
    "    \n",
    "    def _calculate_posterior(self, x):\n",
    "        posteriors = []\n",
    "        for idx, c in enumerate(self.classes):\n",
    "            prior = np.log(self.priors[idx])\n",
    "            class_conditional = np.sum(np.log(self._pdf(idx, x)))\n",
    "            posterior = prior + class_conditional\n",
    "            posteriors.append(posterior)\n",
    "        return posteriors\n",
    "    \n",
    "    def _pdf(self, class_idx, x):\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp(- (x - mean) ** 2 / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def silhouette_score(X, labels):\n",
    "    distances = pairwise_distances(X)\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        same_cluster = distances[i][labels == labels[i]]\n",
    "        other_clusters = distances[i][labels != labels[i]]\n",
    "        a = np.mean(same_cluster)\n",
    "        b = np.min([np.mean(other_clusters[labels == label]) for label in np.unique(labels) if label != labels[i]])\n",
    "        silhouette_scores.append((b - a) / max(a, b))\n",
    "    \n",
    "    return np.mean(silhouette_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_autoencoder(input_dim):\n",
    "    model = Sequential()\n",
    "    # Encoder\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    # Decoder\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(input_dim, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def sentiment_analysis(texts, labels):\n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, labels)\n",
    "    \n",
    "    return model, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mcc(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    numerator = (tp * tn) - (fp * fn)\n",
    "    denominator = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    return numerator / (denominator + 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def hierarchical_clustering(X):\n",
    "    Z = linkage(X, 'ward')\n",
    "    dendrogram(Z)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, input_dim=100, activation='relu'))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dense(28 * 28, activation='tanh'))\n",
    "    model.add(layers.Reshape((28, 28)))\n",
    "    return model\n",
    "\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def arima_forecasting(data, order=(1,1,1)):\n",
    "    model = ARIMA(data, order=order)\n",
    "    model_fit = model.fit()\n",
    "    return model_fit.forecast()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodelsNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading statsmodels-0.14.4-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels) (1.13.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from statsmodels) (2.2.2)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading statsmodels-0.14.4-cp312-cp312-win_amd64.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.8 MB 1.0 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.8/9.8 MB 1.1 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.0/9.8 MB 1.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.3/9.8 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.6/9.8 MB 1.3 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.1/9.8 MB 1.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.4/9.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.4/9.8 MB 1.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.6/9.8 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.9/9.8 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.1/9.8 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.4/9.8 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.4/9.8 MB 1.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.7/9.8 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.7/9.8 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 3.9/9.8 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.2/9.8 MB 1.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.2/9.8 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 4.5/9.8 MB 994.1 kB/s eta 0:00:06\n",
      "   ------------------ --------------------- 4.5/9.8 MB 994.1 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 4.7/9.8 MB 960.2 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 4.7/9.8 MB 960.2 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.0/9.8 MB 949.6 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.0/9.8 MB 949.6 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.2/9.8 MB 929.2 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.2/9.8 MB 929.2 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.2/9.8 MB 929.2 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.5/9.8 MB 878.4 kB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 5.8/9.8 MB 869.8 kB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 5.8/9.8 MB 869.8 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.0/9.8 MB 854.4 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.0/9.8 MB 854.4 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.3/9.8 MB 840.7 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.3/9.8 MB 840.7 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 6.3/9.8 MB 840.7 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 6.6/9.8 MB 813.4 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 6.6/9.8 MB 813.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 6.8/9.8 MB 798.8 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 6.8/9.8 MB 798.8 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 6.8/9.8 MB 798.8 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.1/9.8 MB 780.3 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.1/9.8 MB 780.3 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.1/9.8 MB 780.3 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.3/9.8 MB 752.4 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.3/9.8 MB 752.4 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.3/9.8 MB 752.4 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 7.6/9.8 MB 734.0 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 7.6/9.8 MB 734.0 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 7.9/9.8 MB 720.8 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 7.9/9.8 MB 720.8 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 7.9/9.8 MB 720.8 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 8.1/9.8 MB 704.9 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 8.1/9.8 MB 704.9 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 8.1/9.8 MB 704.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 8.4/9.8 MB 690.7 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 8.4/9.8 MB 690.7 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 8.4/9.8 MB 690.7 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 8.7/9.8 MB 681.3 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.7/9.8 MB 681.3 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 8.9/9.8 MB 671.9 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 8.9/9.8 MB 671.9 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 8.9/9.8 MB 671.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 9.2/9.8 MB 660.9 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.2/9.8 MB 660.9 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.2/9.8 MB 660.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.8 MB 654.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.8 MB 654.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.8 MB 651.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.8 MB 651.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.8/9.8 MB 639.4 kB/s eta 0:00:00\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 statsmodels-0.14.4\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

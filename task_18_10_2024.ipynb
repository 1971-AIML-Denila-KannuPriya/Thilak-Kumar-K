{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import sqrt\n",
    "from typing import List, Tuple\n",
    "\n",
    "def knn_classifier(data_points: List[Tuple[float, float, str]], \n",
    "                   new_point: Tuple[float, float], \n",
    "                   k: int = 3) -> str:\n",
    "    # Calculate Euclidean distance between new point and all data points\n",
    "    distances = []\n",
    "    for (x, y, label) in data_points:\n",
    "        distance = sqrt((x - new_point[0])**2 + (y - new_point[1])**2)\n",
    "        distances.append((distance, label))\n",
    "    \n",
    "    # Sort by distance and take the k nearest neighbors\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    k_nearest = [label for _, label in distances[:k]]\n",
    "    \n",
    "    # Return the most common label\n",
    "    most_common_label = Counter(k_nearest).most_common(1)[0][0]\n",
    "    return most_common_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from statistics import mean, stdev\n",
    "\n",
    "def remove_outliers(data: List[float]) -> List[float]:\n",
    "    # Calculate the mean and standard deviation\n",
    "    data_mean = mean(data)\n",
    "    data_stdev = stdev(data)\n",
    "    \n",
    "    # Define the threshold for outliers (2 * standard deviation)\n",
    "    threshold = 2 * data_stdev\n",
    "    \n",
    "    # Remove points that are more than 2 * standard deviation from the mean\n",
    "    filtered_data = [x for x in data if abs(x - data_mean) <= threshold]\n",
    "    \n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def matrix_multiply(mat1: List[List[int]], mat2: List[List[int]]) -> List[List[int]]:\n",
    "    # Get dimensions of the matrices\n",
    "    rows_mat1, cols_mat1 = len(mat1), len(mat1[0])\n",
    "    rows_mat2, cols_mat2 = len(mat2), len(mat2[0])\n",
    "    \n",
    "    # Ensure matrices are compatible for multiplication\n",
    "    if cols_mat1 != rows_mat2:\n",
    "        raise ValueError(\"Incompatible matrices for multiplication.\")\n",
    "    \n",
    "    # Initialize the result matrix\n",
    "    result = [[0 for _ in range(cols_mat2)] for _ in range(rows_mat1)]\n",
    "    \n",
    "    # Perform matrix multiplication\n",
    "    for i in range(rows_mat1):\n",
    "        for j in range(cols_mat2):\n",
    "            result[i][j] = sum(mat1[i][k] * mat2[k][j] for k in range(cols_mat1))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from math import sqrt\n",
    "\n",
    "def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n",
    "    # Dot product of the two vectors\n",
    "    dot_product = sum(x * y for x, y in zip(vec1, vec2))\n",
    "    \n",
    "    # Magnitude of the vectors\n",
    "    magnitude_vec1 = sqrt(sum(x**2 for x in vec1))\n",
    "    magnitude_vec2 = sqrt(sum(y**2 for y in vec2))\n",
    "    \n",
    "    # Cosine similarity calculation\n",
    "    if magnitude_vec1 == 0 or magnitude_vec2 == 0:\n",
    "        return 0.0\n",
    "    return dot_product / (magnitude_vec1 * magnitude_vec2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class MinHeap:\n",
    "    def __init__(self):\n",
    "        self.heap = []\n",
    "    \n",
    "    def insert(self, value: int) -> None:\n",
    "        heapq.heappush(self.heap, value)\n",
    "    \n",
    "    def get_min(self) -> int:\n",
    "        return self.heap[0] if self.heap else None\n",
    "    \n",
    "    def extract_min(self) -> int:\n",
    "        return heapq.heappop(self.heap) if self.heap else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def svm_classifier(data_points: List[Tuple[float, float, str]], \n",
    "                   new_point: Tuple[float, float]) -> str:\n",
    "    # Dummy implementation using a linear kernel (actual implementation would be more complex)\n",
    "    # In practice, you'd use a library like scikit-learn to handle SVMs.\n",
    "    # For simplicity, this is a placeholder implementation.\n",
    "    \n",
    "    # Calculate a simple decision boundary (example logic for a linear kernel)\n",
    "    weights = (1.0, 1.0)  # Example weights\n",
    "    bias = 0.0\n",
    "    \n",
    "    # Linear decision function\n",
    "    decision = new_point[0] * weights[0] + new_point[1] * weights[1] + bias\n",
    "    \n",
    "    return 'class_1' if decision > 0 else 'class_2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from statistics import mean, stdev\n",
    "\n",
    "def calculate_z_scores(data: List[float]) -> List[float]:\n",
    "    data_mean = mean(data)\n",
    "    data_stdev = stdev(data)\n",
    "    \n",
    "    z_scores = [(x - data_mean) / data_stdev for x in data]\n",
    "    \n",
    "    return z_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from random import sample\n",
    "from math import sqrt\n",
    "\n",
    "def euclidean_distance(p1: Tuple[float, float], p2: Tuple[float, float]) -> float:\n",
    "    return sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "def k_means_clustering(data_points: List[Tuple[float, float]], k: int) -> List[Tuple[float, float]]:\n",
    "    # Initialize centroids randomly from the data points\n",
    "    centroids = sample(data_points, k)\n",
    "    \n",
    "    for _ in range(100):  # Arbitrary number of iterations\n",
    "        # Assign points to nearest centroid\n",
    "        clusters = {i: [] for i in range(k)}\n",
    "        for point in data_points:\n",
    "            distances = [euclidean_distance(point, centroid) for centroid in centroids]\n",
    "            nearest_centroid = distances.index(min(distances))\n",
    "            clusters[nearest_centroid].append(point)\n",
    "        \n",
    "        # Recalculate centroids\n",
    "        for i in range(k):\n",
    "            if clusters[i]:\n",
    "                centroids[i] = (\n",
    "                    sum([p[0] for p in clusters[i]]) / len(clusters[i]),\n",
    "                    sum([p[1] for p in clusters[i]]) / len(clusters[i])\n",
    "                )\n",
    "    \n",
    "    return centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def f1_score(true_labels: List[int], predicted_labels: List[int]) -> float:\n",
    "    tp = sum([1 for t, p in zip(true_labels, predicted_labels) if t == 1 and p == 1])\n",
    "    fp = sum([1 for t, p in zip(true_labels, predicted_labels) if t == 0 and p == 1])\n",
    "    fn = sum([1 for t, p in zip(true_labels, predicted_labels) if t == 1 and p == 0])\n",
    "    \n",
    "    if tp == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def create_histogram(data: List[float], bins: int) -> Dict[str, int]:\n",
    "    min_val, max_val = min(data), max(data)\n",
    "    bin_size = (max_val - min_val) / bins\n",
    "    histogram = {}\n",
    "    \n",
    "    for i in range(bins):\n",
    "        bin_range = f\"{round(min_val + i*bin_size, 2)}-{round(min_val + (i+1)*bin_size, 2)}\"\n",
    "        histogram[bin_range] = sum([1 for x in data if min_val + i*bin_size <= x < min_val + (i+1)*bin_size])\n",
    "    \n",
    "    return histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def decision_tree_classifier(data_points: List[Tuple[List[float], str]], \n",
    "                             new_point: List[float]) -> str:\n",
    "    # Placeholder for actual decision tree logic (use scikit-learn in practice)\n",
    "    return data_points[0][1]  # Just returning the label of the first point (as a placeholder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def min_max_normalization(data: List[float]) -> List[float]:\n",
    "    min_val, max_val = min(data), max(data)\n",
    "    return [(x - min_val) / (max_val - min_val) for x in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from math import sqrt\n",
    "\n",
    "def euclidean_distance(point1: List[float], point2: List[float]) -> float:\n",
    "    return sqrt(sum((x - y)**2 for x, y in zip(point1, point2)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
